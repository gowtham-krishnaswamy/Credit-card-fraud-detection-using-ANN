{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREDIT CARD FRADULENT TRANSACTION USING ARTIFICAL NEURAL NETWORKS\n",
    "\n",
    "Data : https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "The data is obtained from Kaggle and can be downloaded using above link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas_datareader import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Time', axis = 1) #we are dropping time because it is just the time fro first transaction and it does not determine if a transaction is valid or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the features in X and the class in y variable\n",
    "X = data.iloc[:, data.columns != 'Class']\n",
    "y = data.iloc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29)\n",
      "(284807, 1)\n"
     ]
    }
   ],
   "source": [
    "#printing X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x298bb51f108>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Draw a bar graph of correlation between each feature and class variable\n",
    "data.corrwith(data.Class).plot.bar(figsize = (14, 8), title = \"Correlation with Class column\", grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-56.40751</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.45493</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>23.745136</td>\n",
       "      <td>...</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1         V2         V3         V4          V5         V6  \\\n",
       "min -56.40751 -72.715728 -48.325589  -5.683171 -113.743307 -26.160506   \n",
       "max   2.45493  22.057729   9.382558  16.875344   34.801666  73.301626   \n",
       "\n",
       "             V7         V8         V9        V10  ...        V20        V21  \\\n",
       "min  -43.557242 -73.216718 -13.434066 -24.588262  ... -54.497720 -34.830382   \n",
       "max  120.589494  20.007208  15.594995  23.745136  ...  39.420904  27.202839   \n",
       "\n",
       "           V22        V23       V24        V25       V26        V27  \\\n",
       "min -10.933144 -44.807735 -2.836627 -10.295397 -2.604551 -22.565679   \n",
       "max  10.503090  22.528412  4.584549   7.519589  3.517346  31.612198   \n",
       "\n",
       "           V28    Amount  \n",
       "min -15.430084      0.00  \n",
       "max  33.847808  25691.16  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding range of each column\n",
    "def minMax(x):\n",
    "    return pd.Series(index=['min','max'],data=[x.min(),x.max()])\n",
    "X.apply(minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gowth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-56.40751</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.353229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.45493</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>23.745136</td>\n",
       "      <td>...</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>102.362243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1         V2         V3         V4          V5         V6  \\\n",
       "min -56.40751 -72.715728 -48.325589  -5.683171 -113.743307 -26.160506   \n",
       "max   2.45493  22.057729   9.382558  16.875344   34.801666  73.301626   \n",
       "\n",
       "             V7         V8         V9        V10  ...        V20        V21  \\\n",
       "min  -43.557242 -73.216718 -13.434066 -24.588262  ... -54.497720 -34.830382   \n",
       "max  120.589494  20.007208  15.594995  23.745136  ...  39.420904  27.202839   \n",
       "\n",
       "           V22        V23       V24        V25       V26        V27  \\\n",
       "min -10.933144 -44.807735 -2.836627 -10.295397 -2.604551 -22.565679   \n",
       "max  10.503090  22.528412  4.584549   7.519589  3.517346  31.612198   \n",
       "\n",
       "           V28      Amount  \n",
       "min -15.430084   -0.353229  \n",
       "max  33.847808  102.362243  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From above output we can see that we have to scale only amount. So scaling amount to reduce its range\n",
    "scaler = StandardScaler()\n",
    "X['Amount'] = scaler.fit_transform(X['Amount'].values.reshape(-1, 1))\n",
    "X.apply(minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 29) (227845, 1) (56962, 29) (56962, 1)\n"
     ]
    }
   ],
   "source": [
    "#splitting into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 15)                450       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 706\n",
      "Trainable params: 706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(activation = 'relu', units = 15, input_dim = 29))\n",
    "model.add(Dense(activation = 'relu', units = 15))\n",
    "model.add(Dense(activation = 'sigmoid', units  = 1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 0.0035 - accuracy: 0.9981\n",
      "Epoch 2/100\n",
      "227845/227845 [==============================] - 3s 12us/step - loss: 0.0018 - accuracy: 0.9982\n",
      "Epoch 3/100\n",
      "227845/227845 [==============================] - 3s 12us/step - loss: 0.0018 - accuracy: 0.9982\n",
      "Epoch 4/100\n",
      "227845/227845 [==============================] - 3s 12us/step - loss: 0.0018 - accuracy: 0.9982\n",
      "Epoch 5/100\n",
      "227845/227845 [==============================] - 3s 13us/step - loss: 0.0018 - accuracy: 0.9982\n",
      "Epoch 6/100\n",
      "227845/227845 [==============================] - 3s 13us/step - loss: 0.0018 - accuracy: 0.9982\n",
      "Epoch 7/100\n",
      "227845/227845 [==============================] - 3s 13us/step - loss: 9.1527e-04 - accuracy: 0.9991\n",
      "Epoch 8/100\n",
      "227845/227845 [==============================] - 3s 13us/step - loss: 5.5356e-04 - accuracy: 0.9994\n",
      "Epoch 9/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 5.3366e-04 - accuracy: 0.9994\n",
      "Epoch 10/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 5.1239e-04 - accuracy: 0.9995\n",
      "Epoch 11/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 4.9353e-04 - accuracy: 0.9994\n",
      "Epoch 12/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 4.6911e-04 - accuracy: 0.9995\n",
      "Epoch 13/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 4.5298e-04 - accuracy: 0.9995\n",
      "Epoch 14/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 4.3713e-04 - accuracy: 0.9995\n",
      "Epoch 15/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.9754e-04 - accuracy: 0.9996\n",
      "Epoch 16/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 3.9771e-04 - accuracy: 0.9995\n",
      "Epoch 17/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 3.8092e-04 - accuracy: 0.9996\n",
      "Epoch 18/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.7519e-04 - accuracy: 0.9996\n",
      "Epoch 19/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.5065e-04 - accuracy: 0.9996\n",
      "Epoch 20/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.5214e-04 - accuracy: 0.9996\n",
      "Epoch 21/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.4421e-04 - accuracy: 0.9996\n",
      "Epoch 22/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.3807e-04 - accuracy: 0.9996\n",
      "Epoch 23/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.1970e-04 - accuracy: 0.9996\n",
      "Epoch 24/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.3727e-04 - accuracy: 0.9996\n",
      "Epoch 25/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.5232e-04 - accuracy: 0.9996\n",
      "Epoch 26/100\n",
      "227845/227845 [==============================] - ETA: 0s - loss: 3.2744e-04 - accuracy: 0.99 - 3s 15us/step - loss: 3.2978e-04 - accuracy: 0.9996\n",
      "Epoch 27/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.4579e-04 - accuracy: 0.9996\n",
      "Epoch 28/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.0893e-04 - accuracy: 0.9997\n",
      "Epoch 29/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.1648e-04 - accuracy: 0.9997\n",
      "Epoch 30/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.3761e-04 - accuracy: 0.9996\n",
      "Epoch 31/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.1806e-04 - accuracy: 0.9997\n",
      "Epoch 32/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.1240e-04 - accuracy: 0.9997\n",
      "Epoch 33/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.0524e-04 - accuracy: 0.9997\n",
      "Epoch 34/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.0846e-04 - accuracy: 0.9997\n",
      "Epoch 35/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.9983e-04 - accuracy: 0.9997\n",
      "Epoch 36/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.1213e-04 - accuracy: 0.9997\n",
      "Epoch 37/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8681e-04 - accuracy: 0.9997\n",
      "Epoch 38/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.0748e-04 - accuracy: 0.9997\n",
      "Epoch 39/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.9906e-04 - accuracy: 0.9997\n",
      "Epoch 40/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.9879e-04 - accuracy: 0.9997\n",
      "Epoch 41/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8538e-04 - accuracy: 0.9997\n",
      "Epoch 42/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.1022e-04 - accuracy: 0.9997\n",
      "Epoch 43/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 3.0079e-04 - accuracy: 0.9997\n",
      "Epoch 44/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.9723e-04 - accuracy: 0.9997\n",
      "Epoch 45/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8869e-04 - accuracy: 0.9997\n",
      "Epoch 46/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8778e-04 - accuracy: 0.9997\n",
      "Epoch 47/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.7407e-04 - accuracy: 0.9997\n",
      "Epoch 48/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8142e-04 - accuracy: 0.9997\n",
      "Epoch 49/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.7561e-04 - accuracy: 0.9997\n",
      "Epoch 50/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.7139e-04 - accuracy: 0.9997\n",
      "Epoch 51/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8196e-04 - accuracy: 0.9997\n",
      "Epoch 52/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.5723e-04 - accuracy: 0.9997\n",
      "Epoch 53/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8292e-04 - accuracy: 0.9997\n",
      "Epoch 54/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8512e-04 - accuracy: 0.9997\n",
      "Epoch 55/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8111e-04 - accuracy: 0.9997\n",
      "Epoch 56/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.7282e-04 - accuracy: 0.9997\n",
      "Epoch 57/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.7640e-04 - accuracy: 0.9997\n",
      "Epoch 58/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8063e-04 - accuracy: 0.9997\n",
      "Epoch 59/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.9829e-04 - accuracy: 0.9997\n",
      "Epoch 60/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8950e-04 - accuracy: 0.9997\n",
      "Epoch 61/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.6334e-04 - accuracy: 0.9997\n",
      "Epoch 62/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.9208e-04 - accuracy: 0.9997\n",
      "Epoch 63/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.6865e-04 - accuracy: 0.9997\n",
      "Epoch 64/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.6939e-04 - accuracy: 0.9997\n",
      "Epoch 65/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.9261e-04 - accuracy: 0.9997\n",
      "Epoch 66/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.6222e-04 - accuracy: 0.9997\n",
      "Epoch 67/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5355e-04 - accuracy: 0.9997\n",
      "Epoch 68/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.7183e-04 - accuracy: 0.9997\n",
      "Epoch 69/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.7905e-04 - accuracy: 0.9997\n",
      "Epoch 70/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.8327e-04 - accuracy: 0.9997\n",
      "Epoch 71/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.6677e-04 - accuracy: 0.9997\n",
      "Epoch 72/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8033e-04 - accuracy: 0.9997\n",
      "Epoch 73/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.5864e-04 - accuracy: 0.9997\n",
      "Epoch 74/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.6406e-04 - accuracy: 0.9997\n",
      "Epoch 75/100\n",
      "227845/227845 [==============================] - 3s 15us/step - loss: 2.8906e-04 - accuracy: 0.9997\n",
      "Epoch 76/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 3.0138e-04 - accuracy: 0.9997\n",
      "Epoch 77/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 3.0556e-04 - accuracy: 0.9997\n",
      "Epoch 78/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.7878e-04 - accuracy: 0.9997\n",
      "Epoch 79/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.7137e-04 - accuracy: 0.9997\n",
      "Epoch 80/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5222e-04 - accuracy: 0.9997\n",
      "Epoch 81/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.6941e-04 - accuracy: 0.9997\n",
      "Epoch 82/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5885e-04 - accuracy: 0.9997\n",
      "Epoch 83/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5754e-04 - accuracy: 0.9997\n",
      "Epoch 84/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.6114e-04 - accuracy: 0.9997\n",
      "Epoch 85/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.6802e-04 - accuracy: 0.9997\n",
      "Epoch 86/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5888e-04 - accuracy: 0.9997\n",
      "Epoch 87/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5590e-04 - accuracy: 0.9997\n",
      "Epoch 88/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.4201e-04 - accuracy: 0.9997\n",
      "Epoch 89/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.4990e-04 - accuracy: 0.9997\n",
      "Epoch 90/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.4767e-04 - accuracy: 0.9997\n",
      "Epoch 91/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5974e-04 - accuracy: 0.9997\n",
      "Epoch 92/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5287e-04 - accuracy: 0.9997\n",
      "Epoch 93/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.6071e-04 - accuracy: 0.9997\n",
      "Epoch 94/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.6246e-04 - accuracy: 0.9997\n",
      "Epoch 95/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.3721e-04 - accuracy: 0.9998\n",
      "Epoch 96/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5366e-04 - accuracy: 0.9997\n",
      "Epoch 97/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.9498e-04 - accuracy: 0.9997\n",
      "Epoch 98/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5936e-04 - accuracy: 0.9997\n",
      "Epoch 99/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.6427e-04 - accuracy: 0.9997\n",
      "Epoch 100/100\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 2.5358e-04 - accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "model_fit_data = model.fit(X_train, y_train, epochs = 100, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pred >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56962/56962 [==============================] - 1s 14us/step\n",
      "[0.0004994165700310104, 0.9994557499885559]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(score) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
